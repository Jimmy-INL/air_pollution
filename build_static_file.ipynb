{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build static feature file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import geopy\n",
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bounding box\n",
    "UP_LEFT = (38.008050, -122.536985)    \n",
    "UP_RIGHT = (38.008050, -122.186437)   \n",
    "DOWN_RIGHT = (37.701933, -122.186437) \n",
    "DOWN_LEFT = (37.701933, -122.536985) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAYBE DON'T RELY ON A CSV\n",
    "# load in the grid from csv file\n",
    "vsensors_df = pd.read_csv('./data/500m_grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAYBE DON'T RELY ON A CSV\n",
    "# get elevations from csv file and merge into dataframe\n",
    "def getElevations(data_df, filename):\n",
    "    \"\"\"\n",
    "    This function takes as input a dataframe with latitutes and longitudes and \n",
    "    the filepath to a csv file with the same latitudes and longitudes and elevations.\n",
    "    It returns a dataframe that includes the elevations. \n",
    "    \"\"\"\n",
    "    \n",
    "    elev_df = pd.read_csv(filename, header='infer')\n",
    "    elev_df = elev_df[['x','y','elevation']]\n",
    "    \n",
    "    data_df = pd.merge(data_df, elev_df)\n",
    "    if data_df.elevation.isna().sum() > 0:\n",
    "        print(\"Error. Not all elevations were found.\")\n",
    "    \n",
    "    return(data_df)\n",
    "\n",
    "vsensors_df = getElevations(vsensors_df, './data/grid_elevations.csv')\n",
    "\n",
    "# set a few grid points at seashore and read from TIF as ocean to 0\n",
    "vsensors_df.elevation.replace(-32768, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove virtual sensors that are in water\n",
    "vsensors_df = vsensors_df[vsensors_df.in_water == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_lat</th>\n",
       "      <th>max_lat</th>\n",
       "      <th>min_lon</th>\n",
       "      <th>max_lon</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>center_lat</th>\n",
       "      <th>center_lon</th>\n",
       "      <th>in_water</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>37.822662</td>\n",
       "      <td>37.826210</td>\n",
       "      <td>-122.536985</td>\n",
       "      <td>-122.532493</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>37.824436</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>False</td>\n",
       "      <td>-2000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37.826210</td>\n",
       "      <td>37.829757</td>\n",
       "      <td>-122.536985</td>\n",
       "      <td>-122.532493</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>37.827984</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>False</td>\n",
       "      <td>-2000</td>\n",
       "      <td>-32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37.829757</td>\n",
       "      <td>37.833305</td>\n",
       "      <td>-122.536985</td>\n",
       "      <td>-122.532493</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>37.831531</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>False</td>\n",
       "      <td>-2000</td>\n",
       "      <td>-32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37.833305</td>\n",
       "      <td>37.836852</td>\n",
       "      <td>-122.536985</td>\n",
       "      <td>-122.532493</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>37.835079</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>False</td>\n",
       "      <td>5159</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>37.836852</td>\n",
       "      <td>37.840400</td>\n",
       "      <td>-122.536985</td>\n",
       "      <td>-122.532493</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>37.838626</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>False</td>\n",
       "      <td>7053</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     min_lat    max_lat     min_lon     max_lon  x   y  center_lat  \\\n",
       "0  37.822662  37.826210 -122.536985 -122.532493  0  34   37.824436   \n",
       "1  37.826210  37.829757 -122.536985 -122.532493  0  35   37.827984   \n",
       "2  37.829757  37.833305 -122.536985 -122.532493  0  36   37.831531   \n",
       "3  37.833305  37.836852 -122.536985 -122.532493  0  37   37.835079   \n",
       "4  37.836852  37.840400 -122.536985 -122.532493  0  38   37.838626   \n",
       "\n",
       "   center_lon  in_water  ndvi  elevation  \n",
       "0 -122.534739     False -2000         17  \n",
       "1 -122.534739     False -2000     -32768  \n",
       "2 -122.534739     False -2000     -32768  \n",
       "3 -122.534739     False  5159         55  \n",
       "4 -122.534739     False  7053        132  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAYBE DON'T RELY ON A CSV\n",
    "# add NDVI vegetation data\n",
    "vsensors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Input: two tuples, each containing (lat, lon)\n",
    "    Output: distance between the two coordinates in kilometers\n",
    "    \"\"\"\n",
    "\n",
    "    origin = geopy.point.Point(origin)\n",
    "    destination = geopy.point.Point(destination)\n",
    "    distance = geopy.distance.distance(origin, destination).km\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-59e633f612ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsensors_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_coord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid_coord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mkNN_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mvsensors_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NN_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkNN_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "# CURRENTLY THIS TAKES 50 MINUTES. SPEED UP WITH LAMBDAS POSSIBLE?\n",
    "# for each virtual sensor, find k closest\n",
    "getreading_df = pd.read_json(path_or_buf=\"https://www.purpleair.com/json\") # get fresh data from purple air\n",
    "k = 5\n",
    "\n",
    "# get k-NN sensor IDs\n",
    "kNN_list = []\n",
    "for grid_coord in rsensors_df.columns[4:]:\n",
    "    temp_df = rsensors_df[['ID', grid_coord]]\n",
    "    temp_df.sort_values(by=[grid_coord], axis=0, ascending=True, inplace=True)\n",
    "    kNN_list.append(list(temp_df.ID[0:k]))\n",
    "vsensors_df['NN_list'] = kNN_list \n",
    "\n",
    "# reduce data to what we need\n",
    "rsensors_df = pd.DataFrame.from_records(getreading_df.results)\n",
    "rsensors_df = rsensors_df[['ID', 'Lat', 'Lon']]\n",
    "rsensors_df = rsensors_df[(rsensors_df.Lat <= UP_LEFT[0]) & (rsensors_df.Lat >= DOWN_LEFT[0]) & \n",
    "                    (rsensors_df.Lon >= UP_LEFT[1]) & (rsensors_df.Lon <= UP_RIGHT[1])] # just keep sensors in bounding box\n",
    "rsensors_df['coords'] = list(zip(rsensors_df.Lat, rsensors_df.Lon))\n",
    "\n",
    "# remove all the double entries for sensors\n",
    "rsensors_df.drop_duplicates(subset =\"coords\", inplace = True) \n",
    "\n",
    "# build dataframe of distances between real and virtual sensors\n",
    "empty_col = [100000] * len(rsensors_df) # put out of bounds large value in new empty column\n",
    "for row in range(len(vsensors_df)):\n",
    "    col_name = (vsensors_df.iloc[row].center_lat, vsensors_df.iloc[row].center_lon)\n",
    "    col_name = str(col_name)\n",
    "    rsensors_df[col_name] = empty_col\n",
    "\n",
    "for grid_coord in rsensors_df.columns[4:]:\n",
    "    for sensor_coord in rsensors_df.coords:\n",
    "        distance = calc_distance(tuple(float(s) for s in grid_coord.strip(\"()\").split(\",\")), sensor_coord)\n",
    "        rsensors_df[grid_coord][rsensors_df.coords == sensor_coord] = distance\n",
    "\n",
    "# get k-NN sensor IDs\n",
    "kNN_list = []\n",
    "for grid_coord in rsensors_df.columns[4:]:\n",
    "    temp_df = rsensors_df[['ID', grid_coord]]\n",
    "    temp_df.sort_values(by=[grid_coord], axis=0, ascending=True, inplace=True)\n",
    "    kNN_list.append(list(temp_df.ID[0:k]))\n",
    "vsensors_df['NN_list'] = kNN_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add closest epa sensor\n",
    "\n",
    "# Read historical epa data from s3\n",
    "bucket = \"capstone-air-pollution\"\n",
    "file_name = \"EPA/historical_PM25.csv\"  # historical\n",
    "s3 = boto3.client('s3') \n",
    "obj = s3.get_object(Bucket= bucket, Key= file_name) \n",
    "epa_df = pd.read_csv(obj['Body']) \n",
    "\n",
    "#either use site_name or full_aqs_code... confirm that full_aqs_code is a unique, numeric id for station\n",
    "\n",
    "epa_dict = {}\n",
    "for station in epa_df.SiteName.unique():\n",
    "    row = epa_df[epa_df.SiteName == station].iloc[0]\n",
    "    epa_dict[station] = (row.Latitude, row.Longitude)\n",
    "\n",
    "closest_epa = []\n",
    "for vsensor in range(len(vsensors_df)):\n",
    "    v_coords = (vsensors_df.iloc[vsensor].center_lat, vsensors_df.iloc[vsensor].center_lon)\n",
    "    nn_distance = 0\n",
    "    nn_station = \"\"\n",
    "    for station in epa_dict.keys():\n",
    "        distance = calc_distance(epa_dict[station], v_coords)\n",
    "        if (nn_station == \"\" or nn_distance > distance):\n",
    "            nn_distance = distance\n",
    "            nn_station = station\n",
    "    closest_epa.append(nn_station)\n",
    "\n",
    "vsensors_df['closest_epa'] = closest_epa\n",
    "\n",
    "# this is very fast, but as a lambda:\n",
    "# vsensor['closest_epa'] = vsensors_df.apply(lambda x: closest_epa(x), axis=1)\n",
    "# [bay_and_ocean.contains(pt) for pt in boxes_as_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add closest noaa sensor\n",
    "\n",
    "# read in all ASOS stations w/ lat lon info\n",
    "filepath = \"ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.txt\"\n",
    "stations = [] # an array of each read line\n",
    "for station in pd.read_csv(filepath_or_buffer=filepath , encoding='utf-8', chunksize=1):\n",
    "    stations.append(station.iloc[0,0])\n",
    "\n",
    "# parse ugly text file to dataframe    \n",
    "station_cols = ['usaf','wban_number','descriptor', 'lat','lon','elev_m','begin_date','end_date']\n",
    "stations = stations[17:] # remove header (meta data and column names)\n",
    "station_data = [] # an array of arrays, inner arrays are all data for one record, outer array is all records\n",
    "for station in stations:\n",
    "    data_start = 0 # position after awk location data in each record\n",
    "    USAF = station[0:6]\n",
    "    WBAN = station[7:12]\n",
    "    data_start = station.find('+')\n",
    "    location_string = station[12:data_start]\n",
    "    rest_of_data = station[data_start:].split()    \n",
    "    station_record = [USAF, WBAN, location_string] + rest_of_data\n",
    "    station_data.append(station_record)\n",
    "NOAA_df = pd.DataFrame(station_data, columns = station_cols)\n",
    "\n",
    "# keep on the current Bay Area sensors\n",
    "NOAA_df = NOAA_df.astype({'lat': float, 'lon': float, 'wban_number': int, 'end_date': str})\n",
    "NOAA_df = NOAA_df[(NOAA_df.lat <= UP_LEFT[0]) & (NOAA_df.lat >= DOWN_LEFT[0]) & \n",
    "                    (NOAA_df.lon >= UP_LEFT[1]) & (NOAA_df.lon <= UP_RIGHT[1])] # just keep sensors in bounding box\n",
    "NOAA_df = NOAA_df[NOAA_df.end_date.str.contains(\"2019\")] # just get current sensors, sorta\n",
    "\n",
    "NOAA_dict = {}\n",
    "for station in NOAA_df.descriptor.unique():\n",
    "    row = NOAA_df[NOAA_df.descriptor == station].iloc[0]\n",
    "    NOAA_dict[station] = (row.lat, row.lon)\n",
    "\n",
    "closest_NOAA = []\n",
    "for vsensor in range(len(vsensors_df)):\n",
    "    v_coords = (vsensors_df.iloc[vsensor].center_lat, vsensors_df.iloc[vsensor].center_lon)\n",
    "    nn_distance = 0\n",
    "    nn_station = \"\"\n",
    "    for station in NOAA_dict.keys():\n",
    "        distance = calc_distance(NOAA_dict[station], v_coords)\n",
    "        if (nn_station == \"\" or nn_distance > distance):\n",
    "            nn_distance = distance\n",
    "            nn_station = station\n",
    "    closest_NOAA.append(nn_station)\n",
    "\n",
    "vsensors_df['closest_NOAA'] = closest_NOAA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vsensors_df.to_csv(path_or_buf=\"./data/static_data.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO I NEED THESE?\n",
    "import numpy as np\n",
    "import json\n",
    "from geopy import distance\n",
    "\n",
    "from time import sleep\n",
    "import shapely.geometry\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "from os import path\n",
    "import statistics\n",
    "import boto3\n",
    "import s3fs\n",
    "import sys\n",
    "from fastparquet import ParquetFile\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gmplot\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv built that has:\n",
    "    virtual sensor grid fields\n",
    "    elevation\n",
    "    ocean yes/no\n",
    "    closest epa/noaa\n",
    "    NDVI\n",
    "    closest 5 sensors to virtual sensor grid\n",
    "static_data.csv\n",
    "    \n",
    "each hour, build dataframe from csv adding:\n",
    "    previous 7 days NOAA wind readings -- (lookup by x,y in csv)\n",
    "    previous 7 EPA readings -- (lookup by x,y in csv)\n",
    "    getData() for 7 days -- previous 7 days humidity/temp from nearest PA sensor (lookup by sensor_id in csv, top 5)\n",
    "    ---- grab the point in time that falls on the hour, so 24 * 7 = 168 time point observations going into model\n",
    "X_data_df\n",
    "    \n",
    "from model:\n",
    "    get predicted 168 PM2.5 values for each virtual sensor\n",
    "    average the 168 values down to one\n",
    "    sort highest to lowest readings\n",
    "most_polluted.csv\n",
    "    \n",
    "Freshest possible:\n",
    "    NOAA wind\n",
    "    EPA readings (hourly)\n",
    "    humidity & temp from nearest PA sensor\n",
    "    \n",
    "Occasional refresh:\n",
    "    NDVI\n",
    "    closest sensor to virtual sensor grid\n",
    "    \n",
    "Never refresh:\n",
    "    elevation\n",
    "    ocean yes/no\n",
    "    closest epa/noaa to virtual sensor grid \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
