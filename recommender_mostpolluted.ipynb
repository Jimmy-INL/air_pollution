{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use k-NN model to predict worst air pollution locations on the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from geopy.distance import distance\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import shapely.geometry\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import boto3\n",
    "import s3fs\n",
    "import sys\n",
    "from fastparquet import ParquetFile\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import geopy\n",
    "from geopy import distance\n",
    "import gmplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the grid from csv file\n",
    "boxes = pd.read_csv('data/500m_grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the model from a pickle file\n",
    "from joblib import dump, load\n",
    "model = load('VirtualSensing/models/kNN_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a features dataframe\n",
    "X_data_df = boxes.copy(deep=True) \n",
    "X_data_df = X_data_df[X_data_df.in_water == False]\n",
    "X_data_df = X_data_df.drop(columns = ['min_lat', 'max_lat', 'min_lon', 'max_lon', 'x','y','in_water'])\n",
    "X_data_df.rename(columns={'center_lat': 'lat', 'center_lon': 'lon'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for time_delta for kNN model\n",
    "lats_to_add = list(X_data_df.lat)\n",
    "lons_to_add = list(X_data_df.lon)\n",
    "all_sensors = len(X_data_df)\n",
    "max_time = (pd.Timestamp('2019-09-04 23:50:00') - pd.Timestamp('2019-09-01 00:00:00')) / np.timedelta64(1, 'm')\n",
    "lat = [lats_to_add]\n",
    "lon = [lons_to_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = 0\n",
    "times = [[current_time] * all_sensors]\n",
    "while (current_time <= max_time):\n",
    "    current_time += 10\n",
    "    time = [current_time] * all_sensors\n",
    "    times.append(time)\n",
    "    lat.append(lats_to_add[:])\n",
    "    lon.append(lons_to_add[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lat = [item for sublist in lat for item in sublist]\n",
    "flat_lon = [item for sublist in lon for item in sublist]\n",
    "flat_times = [item for sublist in times for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataframe \n",
    "data = {'lat': flat_lat, 'lon': flat_lon, 'time_delta': flat_times}\n",
    "X_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>pred_PM2_5</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>37.824436</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>0</td>\n",
       "      <td>2.921875</td>\n",
       "      <td>2.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37.827984</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>0</td>\n",
       "      <td>2.921875</td>\n",
       "      <td>2.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37.831531</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>0</td>\n",
       "      <td>2.921875</td>\n",
       "      <td>2.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37.835079</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>0</td>\n",
       "      <td>2.921875</td>\n",
       "      <td>2.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>37.838626</td>\n",
       "      <td>-122.534739</td>\n",
       "      <td>0</td>\n",
       "      <td>2.921875</td>\n",
       "      <td>2.921875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  time_delta  pred_PM2_5       avg\n",
       "0  37.824436 -122.534739           0    2.921875  2.921875\n",
       "1  37.827984 -122.534739           0    2.921875  2.921875\n",
       "2  37.831531 -122.534739           0    2.921875  2.921875\n",
       "3  37.835079 -122.534739           0    2.921875  2.921875\n",
       "4  37.838626 -122.534739           0    2.921875  2.921875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2.448788e+06</td>\n",
       "      <td>2.448788e+06</td>\n",
       "      <td>2.448788e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.786556e+01</td>\n",
       "      <td>-1.223379e+02</td>\n",
       "      <td>2.880000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8.985630e-02</td>\n",
       "      <td>1.114132e-01</td>\n",
       "      <td>1.665653e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.770371e+01</td>\n",
       "      <td>-1.225347e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.778540e+01</td>\n",
       "      <td>-1.224449e+02</td>\n",
       "      <td>1.440000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.787409e+01</td>\n",
       "      <td>-1.223057e+02</td>\n",
       "      <td>2.880000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.794496e+01</td>\n",
       "      <td>-1.222383e+02</td>\n",
       "      <td>4.320000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.800869e+01</td>\n",
       "      <td>-1.221844e+02</td>\n",
       "      <td>5.760000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lat           lon    time_delta\n",
       "count  2.448788e+06  2.448788e+06  2.448788e+06\n",
       "mean   3.786556e+01 -1.223379e+02  2.880000e+03\n",
       "std    8.985630e-02  1.114132e-01  1.665653e+03\n",
       "min    3.770371e+01 -1.225347e+02  0.000000e+00\n",
       "25%    3.778540e+01 -1.224449e+02  1.440000e+03\n",
       "50%    3.787409e+01 -1.223057e+02  2.880000e+03\n",
       "75%    3.794496e+01 -1.222383e+02  4.320000e+03\n",
       "max    3.800869e+01 -1.221844e+02  5.760000e+03"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = model.predict(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['pred_PM2_5'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['avg'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes['avg_PM2_5'] = [0] * len(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in range(len(boxes)):\n",
    "    boxes.avg_PM2_5.iloc[sensor] = X_df[(X_df.lat == boxes.center_lat.iloc[sensor]) & \n",
    "         (X_df.lon == boxes.center_lon.iloc[sensor])].pred_PM2_5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for mapping\n",
    "map_df = boxes[boxes.in_water == False]\n",
    "map_df = map_df.sort_values(by='avg_PM2_5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top most polluted virtual sensor locations\n",
    "\n",
    "HOW_MANY = 30 # how many sensors to place\n",
    "\n",
    "gmap3=gmplot.GoogleMapPlotter(map_df.center_lat.iloc[0], map_df.center_lon.iloc[0], 10, apikey = \"AIzaSyA2TdrwntJVu6IuS_3fOY7WLTLvhl3xntk\")\n",
    "gmap3.coloricon = \"http://www.googlemapsmarkers.com/v1/%s/\"\n",
    "for sensor in range(HOW_MANY):\n",
    "    gmap3.marker(map_df.center_lat.iloc[sensor], map_df.center_lon.iloc[sensor], color='cornflowerblue', title=sensor)#, title=map_df.pred_PM2_5)\n",
    "gmap3.draw(\"data/grid_pred_map.html\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from geopy.distance import distance\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import shapely.geometry\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# libraries\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import boto3\n",
    "import s3fs\n",
    "import sys\n",
    "from fastparquet import ParquetFile\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import geopy\n",
    "from geopy import distance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrid():\n",
    "    # Set up projections\n",
    "    p_ll = pyproj.Proj(init='epsg:4283') # grid in lat/lon\n",
    "    p_mt = pyproj.Proj(init='epsg:3857') # metric; same as EPSG:900913\n",
    "\n",
    "    # Create corners of rectangle to be transformed to a grid\n",
    "    MIN_LAT = 37.701933\n",
    "    MAX_LAT = 38.008050\n",
    "    MIN_LON = -122.536985\n",
    "    MAX_LON = -122.186437\n",
    "    sw = shapely.geometry.Point((MIN_LON, MIN_LAT))\n",
    "    ne = shapely.geometry.Point((MAX_LON,MAX_LAT))\n",
    "\n",
    "    stepsize = 500 # 0.5 km grid step size\n",
    "\n",
    "    # Project corners to target projection\n",
    "    s = pyproj.transform(p_ll, p_mt, sw.x, sw.y) # Transform NW point to 3857\n",
    "    e = pyproj.transform(p_ll, p_mt, ne.x, ne.y) # .. same for SE\n",
    "\n",
    "    # Iterate over 2D area\n",
    "    boxes = []\n",
    "    min_lon = s[0]\n",
    "    x = 0\n",
    "    while min_lon < e[0]:\n",
    "        max_lon = min_lon + stepsize\n",
    "        min_lat = s[1]\n",
    "        y = 0\n",
    "    \n",
    "        while min_lat < e[1]:\n",
    "            max_lat = min_lat + stepsize\n",
    "            b_left = shapely.geometry.Point(pyproj.transform(p_mt, p_ll, min_lon, min_lat))\n",
    "            t_right = shapely.geometry.Point(pyproj.transform(p_mt, p_ll, max_lon, max_lat))\n",
    "        \n",
    "            bound_box = {'min_lat':b_left.y, 'max_lat':t_right.y, 'min_lon':b_left.x, 'max_lon':t_right.x, 'x': x, 'y':y}\n",
    "        \n",
    "            boxes.append(bound_box)\n",
    "            min_lat = max_lat\n",
    "            y += 1\n",
    "        min_lon = max_lon\n",
    "        x += 1\n",
    "        \n",
    "    boxes = pd.DataFrame(boxes)\n",
    "\n",
    "    # find the center of each box\n",
    "    boxes['center_lat'] = (boxes.min_lat + boxes.max_lat)/2\n",
    "    boxes['center_lon'] = (boxes.min_lon + boxes.max_lon)/2\n",
    "    \n",
    "    base = gpd.read_file(\"bayarea.json\")\n",
    "    \n",
    "    # map every box to whether it overlaps with the bay as defined by the shapefile\n",
    "    boxes['in_water'] = [bay_and_ocean.contains(pt) for pt in boxes_as_points]\n",
    "\n",
    "    # convert lat/lon to Point objects\n",
    "    boxes_as_points = boxes.apply(lambda line: Point(line.center_lon, line.center_lat), axis = 1)\n",
    "    \n",
    "    return(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save grid to csv file\n",
    "boxes[['min_lat', 'max_lat', 'min_lon', 'max_lon', 'x', 'y', 'center_lat',\n",
    "       'center_lon', 'in_water']].to_csv(\"500m_grid.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature data at each center point of the grid\n",
    "created, lat, lon, wind_data, wind_direction, wind_speed, gusts, gust_speed, variable_winds, epa_pm25_value, wkday, \n",
    "temperature, humidity, elevation, hour, month, timeofday_afternoon, timeofday_evening, timeofday_morning, timeofday_night,\n",
    "daytype_Weekday, daytype_Weekend, compass_ERROR, compass_East, compass_Missing, compass_No wind, compass_North, \n",
    "compass_South, compass_West\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "sys.path.append(\"./HistoricalData/\")\n",
    "from getData import get_data\n",
    "\n",
    "UP_LEFT = (38.008050, -122.536985)    \n",
    "UP_RIGHT = (38.008050, -122.186437)   \n",
    "DOWN_RIGHT = (37.701933, -122.186437) \n",
    "DOWN_LEFT = (37.701933, -122.536985)  \n",
    "START_DATE = '2018/09/10' \n",
    "END_DATE = '2019/09/10'   \n",
    "START_HOUR = '0'        \n",
    "END_HOUR = '24'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframe\n",
    "data_df = get_data(UP_LEFT, UP_RIGHT, DOWN_RIGHT, DOWN_LEFT, START_DATE, END_DATE, START_HOUR, END_HOUR, 'Monthly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elevation data\n",
    "elev_df = pd.read_csv('VirtualSensing/sensor_elevations.csv', header='infer', float_precision='high')\n",
    "elev_df = elev_df.drop(columns='resolution')\n",
    "data_df = pd.merge(data_df, elev_df)\n",
    "print(\"How many elevations are missing?\", data_df.elevation.isna().sum())\n",
    "print(\"Shape of the new dataframe:\", data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winnow down the features\n",
    "columns_to_keep = ['created', 'lat', 'lon', 'wind_data', 'wind_direction', 'wind_speed', 'gusts', 'gust_speed', \n",
    "                   'variable_winds', 'variable_wind_info', 'epa_pm25_value', 'wkday', \n",
    "                   'daytype', 'timeofday', 'wind_compass', 'temperature', 'humidity', 'elevation', 'hour', 'month']\n",
    "X_data_df = data_df[columns_to_keep]\n",
    "y_data_df = data_df['2_5um']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_df.wind_data = X_data_df.wind_data.astype(bool)\n",
    "X_data_df.variable_winds = X_data_df.variable_winds.astype(bool)\n",
    "X_data_df.gusts = X_data_df.gusts.astype(bool)\n",
    "X_data_df.daytype = X_data_df.daytype.astype(str)\n",
    "X_data_df.daytype = X_data_df.daytype.astype('category')\n",
    "X_data_df.timeofday = X_data_df.timeofday.astype(str)\n",
    "X_data_df.timeofday = X_data_df.timeofday.astype('category')\n",
    "X_data_df.wind_compass = X_data_df.wind_compass.astype(str)\n",
    "X_data_df.wind_compass = X_data_df.wind_compass.astype('category')\n",
    "X_data_df.wkday = pd.to_numeric(X_data_df.wkday)\n",
    "X_data_df.wkday = X_data_df.wkday.astype('category')\n",
    "X_data_df.hour = X_data_df.hour.astype(int)\n",
    "X_data_df.month = X_data_df.month.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle variable winds missing values \n",
    "vrb_wind_range_readings = 0\n",
    "mid_ranges = list()\n",
    "\n",
    "for row in range(len(X_data_df)):\n",
    "    if X_data_df.variable_winds.iloc[row]:\n",
    "        info = X_data_df.variable_wind_info.iloc[row]\n",
    "        if info:\n",
    "            vrb_wind_range_readings += 1\n",
    "            first, second = info.split('V')\n",
    "            mid_range = int((int(first) + int(second)) / 2)\n",
    "            if (X_data_df.wind_direction.iloc[row] == 'VRB'):\n",
    "                X_data_df.wind_direction.lloc[row] = mid_range\n",
    "            mid_ranges.append(mid_range)\n",
    "\n",
    "replacement = statistics.mode(mid_ranges)\n",
    "X_data_df = X_data_df.replace('VRB', replacement) # give variable wind the most frequent midpoint variable range\n",
    "X_data_df = X_data_df.drop(columns = ['variable_wind_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing wind values with means \n",
    "wind_direction_obs = pd.to_numeric(X_data_df.wind_direction.dropna())\n",
    "wind_direction_avg = wind_direction_obs.mean()\n",
    "wind_direction_avg = int(wind_direction_avg)\n",
    "X_data_df.wind_direction = X_data_df.wind_direction.replace(np.nan, wind_direction_avg) # give missing wind direction the mean\n",
    "X_data_df.wind_direction = X_data_df.wind_direction.replace('', wind_direction_avg)\n",
    "X_data_df.wind_direction = X_data_df.wind_direction.astype(int)\n",
    "wind_speed_obs = pd.to_numeric(X_data_df.wind_speed.dropna())\n",
    "wind_speed_avg = wind_speed_obs.mean()\n",
    "X_data_df.wind_speed = X_data_df.wind_speed.replace(np.nan, wind_speed_avg) # give missing wind speed the mean\n",
    "X_data_df.wind_speed = X_data_df.wind_speed.replace('', wind_speed_avg)\n",
    "X_data_df.gust_speed = X_data_df.gust_speed.replace(np.nan, 0)\n",
    "X_data_df.gust_speed = X_data_df.gust_speed.replace('', 0)\n",
    "X_data_df.epa_pm25_value = X_data_df.epa_pm25_value.replace(np.nan, X_data_df.epa_pm25_value.mean())\n",
    "X_data_df.temperature = X_data_df.temperature.replace(np.nan, X_data_df.temperature.mean())\n",
    "X_data_df.humidity = X_data_df.humidity.replace(np.nan, X_data_df.humidity.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the categoricals\n",
    "X_data_df = pd.concat([X_data_df,pd.get_dummies(X_data_df['timeofday'], prefix='timeofday')],axis=1)\n",
    "X_data_df = pd.concat([X_data_df,pd.get_dummies(X_data_df['daytype'], prefix='daytype')], axis=1)\n",
    "X_data_df = pd.concat([X_data_df,pd.get_dummies(X_data_df['wind_compass'], prefix='compass')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the original columns that got one hot encoded, type the one hots as bools\n",
    "X_data_df = X_data_df.drop(columns=['timeofday','daytype','wind_compass'])\n",
    "X_data_df.timeofday_afternoon = X_data_df.timeofday_afternoon.astype(bool)\n",
    "X_data_df.timeofday_evening = X_data_df.timeofday_evening.astype(bool)\n",
    "X_data_df.timeofday_morning = X_data_df.timeofday_morning.astype(bool)\n",
    "X_data_df.timeofday_night = X_data_df.timeofday_night.astype(bool)\n",
    "X_data_df.daytype_Weekday = X_data_df.daytype_Weekday.astype(bool)\n",
    "X_data_df.daytype_Weekend = X_data_df.daytype_Weekend.astype(bool)\n",
    "X_data_df.compass_ERROR = X_data_df.compass_ERROR.astype(bool)\n",
    "X_data_df.compass_East = X_data_df.compass_East.astype(bool)\n",
    "X_data_df.compass_Missing = X_data_df.compass_Missing.astype(bool)\n",
    "X_data_df['compass_No wind'] = X_data_df['compass_No wind'].astype(bool)\n",
    "X_data_df.compass_North = X_data_df.compass_North.astype(bool)\n",
    "X_data_df.compass_South = X_data_df.compass_South.astype(bool)\n",
    "X_data_df.compass_West = X_data_df.compass_West.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm no NAs at this point\n",
    "for col in X_data_df.columns:\n",
    "    testy = X_data_df[col]\n",
    "    print(col, testy.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
