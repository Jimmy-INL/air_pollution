{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of PurpleAir's data\n",
    "[PurpleAir](http://www.purpleair.com) sells low-cost air quality sensors that feed data to [real-time maps of PM2.5 pollution](https://www.purpleair.com/map?#11/37.789/-122.2048).   \n",
    "This data will be used for a UC Berkeley capstone project [summarized here](https://docs.google.com/document/d/1NjCpqNd7rDnD6VOExVktGtquRzs21hpwZ8HhLQpYLO8/edit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime, time\n",
    "from dateutil import tz\n",
    "import ast\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "import gmplot\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "from fastparquet import ParquetFile, write\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Folder Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to specify the paths for the data folder in your local machines\n",
    "# Use the variable 'datafolder' to specify the path\n",
    "# Comment out all the data paths except your own\n",
    "# Purple Air data ia assumed to be in a subfolder called 'purpleair' \n",
    "# For example, if the base data folder is '/users/data', purpleair data should be in '/users/data/purpleair'\n",
    "\n",
    "# Angshuman's local path\n",
    "datafolder = \"/Users/apaul2/Documents/_Common/capstone/Project/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data for one full day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is being pulled from the s3 bucket (midscapstone-whos-polluting-my-air) where we are storing all the purple air data files. The data files are being stored in a folder called 'PurpleAir' in this bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>county</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kardia</td>\n",
       "      <td>Greece</td>\n",
       "      <td>None</td>\n",
       "      <td>40.465755</td>\n",
       "      <td>22.992308</td>\n",
       "      <td>None</td>\n",
       "      <td>575 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>Greece</td>\n",
       "      <td>None</td>\n",
       "      <td>40.633926</td>\n",
       "      <td>22.956742</td>\n",
       "      <td>None</td>\n",
       "      <td>546 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>Greece</td>\n",
       "      <td>None</td>\n",
       "      <td>40.597275</td>\n",
       "      <td>22.954437</td>\n",
       "      <td>None</td>\n",
       "      <td>546 46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>Greece</td>\n",
       "      <td>None</td>\n",
       "      <td>40.633927</td>\n",
       "      <td>22.939293</td>\n",
       "      <td>None</td>\n",
       "      <td>546 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keizer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Marion County</td>\n",
       "      <td>45.017528</td>\n",
       "      <td>-123.016639</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>97303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city        country         county        lat         lon   state  \\\n",
       "0        Kardia         Greece           None  40.465755   22.992308    None   \n",
       "1  Thessaloniki         Greece           None  40.633926   22.956742    None   \n",
       "2  Thessaloniki         Greece           None  40.597275   22.954437    None   \n",
       "3  Thessaloniki         Greece           None  40.633927   22.939293    None   \n",
       "4        Keizer  United States  Marion County  45.017528 -123.016639  Oregon   \n",
       "\n",
       "  zipcode  \n",
       "0  575 00  \n",
       "1  546 36  \n",
       "2  546 46  \n",
       "3  546 24  \n",
       "4   97303  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for existing addresses\n",
    "address_df = pd.read_parquet(\"{}/purpleair/address_latlon.parquet\".format(datafolder))\n",
    "address_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_list = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14']\n",
    "# bay_purple_df = pd.read_parquet(\"{}/purpleair/dailyfiltered/20190914.parquet\".format(datafolder))\n",
    "\n",
    "for i in range(14,31):\n",
    "    bay_purple_df = pd.read_parquet(\"{}/purpleair/dailyfiltered/201909{}.parquet\".format(datafolder, i))\n",
    "\n",
    "# for i in range(len(days_list)):\n",
    "    \n",
    "    bay_purple_latlon_df = bay_purple_df[['device_loc_typ', 'is_owner', 'sensor_id', 'sensor_name',  'parent_id', 'lat', 'lon', 'thingspeak_primary_id', 'thingspeak_primary_id_read_key', 'thingspeak_secondary_id', \n",
    "                                      'thingspeak_secondary_id_read_key', 'sensorhash']]\n",
    "    bay_purple_latlon_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    bay_purple_data_df = bay_purple_df[['a_h', 'high_reading_flag', 'hidden', 'datetime', 'sensorhash']]\n",
    "    bay_purple_data_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     bay_ts_df = pd.read_parquet(\"{}/thingspeak/thingspeak_sep{}.parquet\".format(datafolder,days_list[i]))\n",
    "    bay_ts_df = pd.read_parquet(\"{}/thingspeak/thingspeak_sep{}.parquet\".format(datafolder,i))\n",
    "    # Some numeric columns may have \"nan\" as a string - convert these values to np.nan\n",
    "    # so that the data type of these columns are correctly identified\n",
    "    bay_ts_df[['0_3um', '0_5um', '1_0um', '2_5um', '5_0um', '10_0um', 'pm1_0','pm10_0', 'created', 'pm1_0_atm', 'pm2_5_atm', 'pm10_0_atm', 'uptime',\n",
    "           'rssi', 'temperature', 'humidity', 'pm2_5_cf_1']] = bay_ts_df[['0_3um', '0_5um', '1_0um', '2_5um', '5_0um', '10_0um', 'pm1_0',\n",
    "           'pm10_0', 'created', 'pm1_0_atm', 'pm2_5_atm', 'pm10_0_atm', 'uptime', 'rssi', 'temperature', 'humidity', 'pm2_5_cf_1']].replace(\"nan\", np.nan, regex=True)\n",
    "    bay_ts_df[['0_3um', '0_5um', '1_0um', '2_5um', '5_0um', '10_0um', 'pm1_0','pm10_0', 'created', 'pm1_0_atm', 'pm2_5_atm', 'pm10_0_atm', 'uptime',\n",
    "           'rssi', 'temperature', 'humidity', 'pm2_5_cf_1']] = bay_ts_df[['0_3um', '0_5um', '1_0um', '2_5um', '5_0um', '10_0um', 'pm1_0',\n",
    "           'pm10_0', 'created', 'pm1_0_atm', 'pm2_5_atm', 'pm10_0_atm', 'uptime', 'rssi', 'temperature', 'humidity', 'pm2_5_cf_1']].apply(pd.to_numeric)\n",
    "    \n",
    "    # Merge purple air data with sensor data\n",
    "    # Only keep records having particle data\n",
    "    bay_ts_df = pd.merge(bay_ts_df, bay_purple_latlon_df,  how='left', left_on=['sensorhash'], right_on=['sensorhash'])\n",
    "    bay_ts_df = pd.merge(bay_ts_df, bay_purple_data_df,  how='left', left_on=['sensorhash', 'created'], right_on=['sensorhash', 'datetime'])\n",
    "    \n",
    "    # Join address dataframe with main dataframe\n",
    "    bay_ts_df = pd.merge(bay_ts_df, address_df,  how='left', left_on=['lat','lon'], right_on=['lat','lon'])\n",
    "    \n",
    "    bay_ts_df['created_at'] = bay_ts_df['created_at_x'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%dT%H:%M\"))\n",
    "    bay_ts_df['year'] = bay_ts_df['created_at_x'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y\"))\n",
    "    bay_ts_df['month'] = bay_ts_df['created_at_x'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%m\"))\n",
    "    bay_ts_df['day'] = bay_ts_df['created_at_x'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%d\"))\n",
    "    bay_ts_df['hour'] = bay_ts_df['created_at_x'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%H\"))\n",
    "    bay_ts_df['minute'] = bay_ts_df['created_at_x'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%M\"))\n",
    "    \n",
    "    # Drop unwanted columns\n",
    "    bay_ts_df.drop(['created_at_x', 'sensorhash', 'datetime', 'country','state'], axis = 1, inplace=True)\n",
    "    \n",
    "    # Convert data type of attributes to string\n",
    "    bay_ts_df[['high_reading_flag','sensor_id','parent_id', 'is_owner']] = bay_ts_df[['high_reading_flag','sensor_id','parent_id', 'is_owner']].astype(str)\n",
    "    \n",
    "    # Save final dataframe for future use\n",
    "#     parquet_file = \"{}/pa_ts/201909{}.parquet\".format(datafolder,days_list[i])\n",
    "    parquet_file = \"{}/pa_ts/201909{}.parquet\".format(datafolder,i)\n",
    "    write(parquet_file, bay_ts_df,compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = pd.read_parquet(\"{}/pa_ts/20190930.parquet\".format(datafolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201909300000, 201909300010, 201909300020, 201909300030,\n",
       "       201909300040, 201909300050, 201909300100, 201909300110,\n",
       "       201909300120, 201909300130, 201909300140, 201909300150,\n",
       "       201909300200, 201909300210, 201909300220, 201909300230,\n",
       "       201909300240, 201909300250, 201909300300, 201909300310,\n",
       "       201909300320, 201909300330, 201909300340, 201909300350,\n",
       "       201909300400, 201909300410, 201909300420, 201909300430,\n",
       "       201909300440, 201909300450, 201909300500, 201909300510,\n",
       "       201909300520, 201909300530, 201909300540, 201909300550,\n",
       "       201909300600, 201909300610, 201909300620, 201909300630,\n",
       "       201909300640, 201909300650, 201909300700, 201909300710,\n",
       "       201909300720, 201909300730, 201909300740, 201909300750,\n",
       "       201909300800, 201909300810, 201909300820, 201909300830,\n",
       "       201909300840, 201909300850, 201909300900, 201909300910,\n",
       "       201909300920, 201909300930, 201909300940, 201909300950,\n",
       "       201909301000, 201909301010, 201909301020, 201909301030,\n",
       "       201909301040, 201909301050, 201909301100, 201909301110,\n",
       "       201909301120, 201909301130, 201909301140, 201909301150,\n",
       "       201909301200, 201909301210, 201909301220, 201909301230,\n",
       "       201909301240, 201909301250, 201909301300, 201909301310,\n",
       "       201909301320, 201909301330, 201909301340, 201909301350,\n",
       "       201909301400, 201909301410, 201909301420, 201909301430,\n",
       "       201909301440, 201909301450, 201909301500, 201909301510,\n",
       "       201909301520, 201909301530, 201909301540, 201909301550,\n",
       "       201909301600, 201909301610, 201909301620, 201909301630,\n",
       "       201909301640, 201909301650, 201909301700, 201909301710,\n",
       "       201909301720, 201909301730, 201909301740, 201909301750,\n",
       "       201909301800, 201909301810, 201909301820, 201909301830,\n",
       "       201909301840, 201909301850, 201909301900, 201909301910,\n",
       "       201909301920, 201909301930, 201909301940, 201909301950,\n",
       "       201909302000, 201909302010, 201909302020, 201909302030,\n",
       "       201909302040, 201909302050, 201909302100, 201909302110,\n",
       "       201909302120, 201909302130, 201909302140, 201909302150,\n",
       "       201909302200, 201909302210, 201909302220, 201909302230,\n",
       "       201909302240, 201909302250, 201909302300, 201909302310,\n",
       "       201909302320, 201909302330, 201909302340, 201909302350])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.created.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
