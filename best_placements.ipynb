{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output best placements of new sensors\n",
    "Load in our virtual sensor pollution prediction model, load in our features for the past 7 days, make predictions.  \n",
    "Create a dataframe with the most polluted locations to the least polluted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from joblib import load\n",
    "\n",
    "# angshuman's functions\n",
    "from HistoricalData.getData import getNearestEpaData, getNearestNoaaData, get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_df = pd.read_csv(\"xfile_rf.csv\") # or whatever the filename is saved from Jake's build on the static csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean interpolating where we don't have humidity/temperature\n",
    "# ideally we do this kind of final cleanup in the previous step where we create the csv of features\n",
    "for col in ['temperature', 'humidity']:\n",
    "    v = X_data_df[col].mean()\n",
    "    X_data_df[col].fillna(v, inplace = True)\n",
    "    X_data_df[col].fillna(v, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(\"nn/201901103_RF.joblib\") # or whatever the filename is of the latest model save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_data_df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create dataframe for map to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = pd.DataFrame(X_data_df[['lat','lon', 'created']])\n",
    "map_df['coords'] = list(zip(map_df.lat, map_df.lon))\n",
    "map_df['pred'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### average predictions at each sensor over the time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = map_df.groupby('coords')['pred'].mean()\n",
    "map_df = map_df.drop_duplicates(subset='coords')\n",
    "map_df['avg_preds'] = avg_preds\n",
    "map_df.sort('avg_preds', ascending=False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be able to take this dataframe, drop records outside lat lon range, and grab the top x number of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code for plotting on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(figsize = (10,10))\n",
    "a.scatter(x = df_tmp['x'],\n",
    "          y = df_tmp['y'],\n",
    "          c = preds,\n",
    "          cmap = 'coolwarm',\n",
    "          s = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mean,that's kind of what our distribution looks like\n",
    "\n",
    "### what if we log-transform the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(figsize = (10,10))\n",
    "a.scatter(x = df_tmp['x'],\n",
    "          y = df_tmp['y'],\n",
    "          c = np.log(preds),\n",
    "          cmap = 'seismic',\n",
    "          s = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**that looks better**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# important note, read me\n",
    "Note the dark red near like, land's end. It's possible there is someone smoking there near a sensor and it's making all the neighbors guess slightly more red than usual. We should drop PA sensor readings over a certain threshold (say, 300) so an outlier reading doesn't throw off all neighbor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
